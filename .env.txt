# --- Claves de API para los servicios de datos externos ---
# Cada una de estas claves es necesaria para que el script pueda autenticarse y solicitar datos de estas plataformas.

# Clave de API para acceder a los datos de YouTube (búsquedas, detalles de videos, etc.).
YOUTUBE_API_KEY=your_youtube_api_key_here

# Token de Acceso Personal de GitHub para realizar búsquedas en repositorios y código.
GITHUB_PERSONAL_ACCESS_TOKEN=your_github_api_key_here

# Clave de API para interactuar con Notion (crear y actualizar páginas).
NOTION_API_KEY=your_notion_api_key_here

# Clave de API para SiliconFlow, que podría ser usada por el servidor de ArXiv para procesar PDFs.
SILICONFLOW_API_KEY=your_siliconflow_api_key_here

# Token de Acceso para Supabase, para guardar los resultados de la investigación en la base de datos.
SUPABASE_ACCESS_TOKEN=your_superbase_api_key_here


# --- Configuración Específica de Notion ---

# El ID de la página principal en Notion bajo la cual se crearán todas las páginas de informes nuevas.
NOTION_PARENT_PAGE_ID='your_notion_parent_page_id'


# --- Configuración de Rutas del Sistema ---
# Define rutas importantes para que la aplicación sea portable entre diferentes sistemas.

# Ruta al directorio donde el servidor 'research_hub' descargará los papers.
RESEARCH_PAPERS_DIR="/path/to/your/research-papers"

# Ruta completa al binario ejecutable del servidor 'research_hub'.
RESEARCH_HUB_EXECUTABLE="/path/to/your/rust-research-mcp"


# --- Configuración del Proveedor de IA ---

# Define qué servicio de IA (LLM) se usará para tareas como la extracción de palabras clave o traducciones.
# Opciones válidas: "anthropic", "gemini", "groq", "ollama", "openai".
AI_PROVIDER="openai" 

# Almacena las claves de API para cada uno de los proveedores de IA soportados.
# El script cargará la clave correspondiente al proveedor seleccionado en AI_PROVIDER.
ANTHROPIC_API_KEY="tu_clave_de_anthropic"
GOOGLE_API_KEY="tu_clave_de_gemini"
GROQ_API_KEY="tu_clave_de_groq"
OPENAI_API_KEY="tu_clave_de_openai"

# --- Configuración Opcional de Modelos de IA ---
# Permite especificar qué modelo exacto usar para cada proveedor. Si no se define, se usará un modelo por defecto.

# Modelo específico para Google Gemini (ej. gemini-1.5-flash).
AI_MODEL_GEMINI="gemini-1.5-flash"
# Modelo específico para Groq (ej. llama3-70b-8192).
AI_MODEL_GROQ="llama3-70b-8192"
# Modelo para Ollama, que debe corresponder a un modelo que tengas instalado localmente (ej. llama3).
AI_MODEL_OLLAMA="llama3"
# Modelo específico para Anthropic Claude (ej. claude-3-haiku).
AI_MODEL_ANTHROPIC="claude-3-haiku-20240307"
# Modelo específico para OpenAI (ej. gpt-4o).
AI_MODEL_OPENAI="gpt-4o"
