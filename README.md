# AI Trend Research Engine

Un sistema automatizado y modular para la investigaci√≥n de tendencias en Inteligencia Artificial. Recopila, procesa y analiza datos de m√∫ltiples fuentes para descubrir *insights*, generar informes y mantener un ciclo de vida de palabras clave en constante evoluci√≥n.

![Python Version](https://img.shields.io/badge/python-3.9%2B-blue)![License](https://img.shields.io/badge/license-MIT-green)![Status](https://img.shields.io/badge/status-activo-brightgreen)![Built with](https://img.shields.io/badge/built%20with-asyncio-purple)

<p align="center">
  <strong>Languages:</strong>
  <br>
  <a href="#-english">English</a> | <a href="#-espa√±ol">Espa√±ol</a> | <a href="#-catal√†">Catal√†</a>
</p>

---

<a name="-english"></a>
## üá¨üáß English

<details>
<summary><strong>Table of Contents</strong></summary>

- [üöÄ Key Features](#-key-features-1)
- [üèõÔ∏è System Architecture](#Ô∏è-system-architecture)
- [üíª Tech Stack](#-tech-stack)
- [üõ†Ô∏è Installation and Setup](#Ô∏è-installation-and-setup-1)
- [‚ñ∂Ô∏è Usage](#Ô∏è-usage-1)
- [ü§ù Contributing](#-contributing-1)
- [üìÑ License](#-license-1)

</details>

### AI Trend Research Engine

An automated and modular system for researching trends in Artificial Intelligence. It collects and processes data from multiple platforms (GitHub, YouTube, ArXiv, etc.), uses large language models (LLMs) to extract insights, discover new keywords, and generates comprehensive reports in multiple formats (JSON, Notion, Supabase).

**Note:** This project was developed by modifying the [EmpowerHerDev/ai-trend-research-system](https://github.com/EmpowerHerDev/ai-trend-research-system) project and integrating the custom research server from [Ladvien/research_hub_mcp](https://github.com/Ladvien/research_hub_mcp). The result is a flexible and modular system that now supports multiple large language model (LLM) providers, including **OpenAI (GPT), Google (Gemini), Anthropic (Claude), Groq, and Ollama**. This work is also part of a personal learning journey in the field of artificial intelligence agent development.

### üöÄ Key Features

-   **Multi-Platform Research**: Gathers data from YouTube, GitHub, web searches, ArXiv, HackerNews, and a custom paper research engine.
-   **Multi-LLM Support**: Seamlessly switch between different LLM providers like OpenAI, Gemini, Groq, Anthropic, and local models with Ollama.
-   **AI-Powered Analysis**: Uses LLMs for advanced tasks such as intelligent keyword extraction, dynamic recommendation generation, and multilingual query translation.
-   **Asynchronous Architecture**: Built with `asyncio` for high concurrency and efficiency in handling network I/O and managing multiple data source servers.
-   **Automated Reporting**: Automatically creates detailed reports in **JSON** (for local archiving), **Notion** (for collaborative workspaces), and **Supabase** (for long-term data persistence).
-   **Dynamic Keyword Lifecycle**: Implements a full lifecycle for keywords: discovery, scoring, active research, and history tracking, all managed through simple JSON files.
-   **Decoupled & Standardized**: Uses the **Model Context Protocol (MCP)** to communicate with each platform's server, ensuring a standardized, modular, and easily extensible interface.
-   **Highly Configurable**: All settings (API keys, AI model selection, file paths) are managed through a single `.env` file for easy portability and security.

### üèõÔ∏è System Architecture

The system is designed with a modular architecture where a central orchestrator manages various specialized components. The communication with external data sources is standardized through MCP servers.

```mermaid
graph TD
    subgraph "Core Engine"
        A[ai_trend_researcher.py] --> B{KeywordManager};
        A --> C{MCPClientManager};
        A --> D{DataProcessor};
        A --> E{ReportManager};
    end

    subgraph "AI Integration"
        F[AIClientManager] -- Manages --> G[OpenAI, Gemini, Groq, ...];
        D -- Uses --> F;
    end

    subgraph "Data Sources (via MCP)"
        C -- Connects to --> H[YouTube Server];
        C -- Connects to --> I[GitHub Server];
        C -- Connects to --> J[ArXiv Server];
        C -- Connects to --> K[Web/HackerNews...];
        C -- Connects to --> L[ResearchHub Server];
    end

    subgraph "Output Reports"
        E -- Generates --> M[JSON Files];
        E -- Generates --> N[Notion Pages];
        E -- Generates --> O[Supabase Records];
    end

    B --> A;
```

-   **Orchestrator (`ai_trend_researcher.py`)**: The main script that coordinates the entire research workflow, from loading keywords to generating final reports.
-   **Configuration (`config_manager.py`)**: Loads and validates all environment variables and server settings.
-   **Connectivity (`mcp_client_manager.py`)**: Manages the lifecycle (start, connect, call, stop) of all MCP servers for the data platforms.
-   **AI Factory (`ai_client_manager.py`)**: Provides a unified interface to interact with various LLM providers.
-   **Platform Logic (`platform_handlers.py`)**: Contains the specific logic for querying each platform and standardizing its response.
-   **Analysis (`data_processor.py`)**: Uses LLMs and heuristics to extract new keywords, score them, and generate actionable recommendations.
-   **Reporting (`report_generator.py`)**: Creates the final reports in all supported formats.
-   **Keyword Database (`keyword_manager.py`)**: Manages the state of keywords across research cycles.

### üíª Tech Stack

-   **Backend**: Python 3.9+
-   **Concurrency**: `asyncio`
-   **AI Providers**: OpenAI, Google Gemini, Anthropic Claude, Groq, Ollama
-   **Tool Protocol**: Model Context Protocol (MCP)
-   **Dependencies**: `python-dotenv`, `aiofiles`, provider-specific SDKs (e.g., `openai`, `google-generativeai`)
-   **Prerequisites**: Node.js & npm (to run community MCP servers via `npx`), Rust (optional, to compile the `research_hub` server)

### üõ†Ô∏è Installation and Setup

#### 1. Prerequisites

-   **Python 3.9+**
-   **Node.js and npm** (required for `npx`, which runs the community's MCP servers).
-   **Git**
-   (Optional) **Rust Compiler**, if you want to compile the `research_hub` executable from the source code. Otherwise, you can use a pre-compiled binary.

#### 2. Clone the Repository

```bash
git clone https://github.com/your-user/your-repository.git
cd your-repository
```

#### 3. Install Python Dependencies

It is highly recommended to use a virtual environment.

```bash
python -m venv venv
# On macOS/Linux:
source venv/bin/activate
# On Windows:
venv\Scripts\activate

pip install -r requirements.txt
```

#### 4. Configure Environment Variables

This is the most critical step.

1.  Create your environment file from the example:
    ```bash
    cp .env.example .env
    ```
2.  Open the `.env` file and fill in your API keys and paths. You only need to fill in the keys for the services you intend to use.

    ```env
    # .env

    # --- AI Provider Configuration ---
    # Choose one: "openai", "gemini", "groq", "anthropic", "ollama"
    AI_PROVIDER="openai"

    # Fill in the API keys for the providers you might use.
    OPENAI_API_KEY="sk-..."
    GOOGLE_API_KEY="AIzaSy..."
    GROQ_API_KEY="gsk_..."
    ANTHROPIC_API_KEY="sk-ant-..."
    # No key needed for Ollama

    # --- (Optional) Specific AI Models ---
    AI_MODEL_OPENAI="gpt-4o"
    AI_MODEL_GEMINI="gemini-1.5-flash"
    # ... and so on for other providers

    # --- API Keys for Data Sources ---
    YOUTUBE_API_KEY=AIzaSy...
    GITHUB_PERSONAL_ACCESS_TOKEN=ghp_...

    # --- API Keys for Report Outputs ---
    NOTION_API_KEY=secret_...
    NOTION_PARENT_PAGE_ID=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
    SUPABASE_ACCESS_TOKEN=eyJhbGciOi...

    # --- System Path Configuration (IMPORTANT!) ---
    # MUST be absolute paths.
    RESEARCH_PAPERS_DIR="/path/on/your/machine/research-papers"
    RESEARCH_HUB_EXECUTABLE="/path/on/your/machine/rust-research-mcp"
    ```

#### 5. Set Up the Database (Supabase)

If you plan to use the Supabase integration, make sure your database table matches the schema defined in `supabase_schema.sql`. You can run this script in the SQL editor of your Supabase project.

### ‚ñ∂Ô∏è Usage

The project has two main execution workflows.

#### 1. Daily Trend Research

This is the primary workflow. It runs research on all enabled platforms using the keywords in `keywords/active.json`, analyzes the data, discovers new keywords, and generates reports.

```bash
python ai_trend_researcher.py
```
The script will log its progress to the console. When it finishes, you will find:
- A JSON report in the `reports/` directory.
- A new page in your specified Notion workspace (if configured).
- A new record in your Supabase table (if configured).

#### 2. Deep Dive Research (`research_assistant`)

This advanced script uses the custom `research_hub` server to perform in-depth academic research. It searches for papers, downloads PDFs, and generates bibliographies.

1. Ensure the `RESEARCH_HUB_EXECUTABLE` path in your `.env` is correct.
2. Add search terms to the `terminos.txt` file (one per line).

```bash
python research_assistant.py
```
The results (CSVs, JSONs, BibTeX files, and logs) will be saved in a timestamped subdirectory within `salidas/` to keep each run organized.

### ü§ù Contributing

Contributions are welcome! If you have ideas for improving the project, new platforms to integrate, or find any bugs, please open an issue or submit a pull request.

### üìÑ License

This project is licensed under the MIT License. See the `LICENSE` file for more details.

---

<a name="-espa√±ol"></a>
## üá™üá∏ Espa√±ol

<details>
<summary><strong>Tabla de Contenidos</strong></summary>

- [üöÄ Caracter√≠sticas Principales](#-caracter√≠sticas-principales-1)
- [üèõÔ∏è Arquitectura del Sistema](#Ô∏è-arquitectura-del-sistema)
- [üíª Stack Tecnol√≥gico](#-stack-tecnol√≥gico)
- [üõ†Ô∏è Instalaci√≥n y Configuraci√≥n](#Ô∏è-instalaci√≥n-y-configuraci√≥n-1)
- [‚ñ∂Ô∏è Uso](#Ô∏è-uso-1)
- [ü§ù Contribuciones](#-contribuciones-1)
- [üìÑ Licencia](#-licencia-1)

</details>

### AI Trend Research Engine

Un sistema automatizado y modular para la investigaci√≥n de tendencias en Inteligencia Artificial. Recopila y procesa datos de m√∫ltiples plataformas (GitHub, YouTube, ArXiv, etc.), utiliza modelos de lenguaje (LLMs) para extraer *insights*, descubrir nuevas palabras clave y genera informes completos en m√∫ltiples formatos (JSON, Notion, Supabase).

**Nota:** Este proyecto ha sido desarrollado modificando el proyecto [EmpowerHerDev/ai-trend-research-system](https://github.com/EmpowerHerDev/ai-trend-research-system) e integrando el servidor de investigaci√≥n personalizado de [Ladvien/research_hub_mcp](https://github.com/Ladvien/research_hub_mcp). El resultado es un sistema flexible y modular que ahora es compatible con m√∫ltiples proveedores de modelos de lenguaje grande (LLM), incluyendo **OpenAI (GPT), Google (Gemini), Anthropic (Claude), Groq y Ollama**. Este trabajo tambi√©n forma parte de un proceso de aprendizaje personal en el campo del desarrollo de agentes de inteligencia artificial.

### üöÄ Caracter√≠sticas Principales

-   **Investigaci√≥n Multiplataforma**: Recopila datos de YouTube, GitHub, b√∫squedas web, ArXiv, HackerNews y un motor de investigaci√≥n de *papers* personalizado.
-   **Soporte Multi-LLM**: Cambia f√°cilmente entre diferentes proveedores de LLM como OpenAI, Gemini, Groq, Anthropic y modelos locales con Ollama.
-   **An√°lisis con IA**: Utiliza LLMs para tareas avanzadas como la extracci√≥n inteligente de palabras clave, la generaci√≥n de recomendaciones din√°micas y la traducci√≥n de consultas multiling√ºes.
-   **Arquitectura As√≠ncrona**: Construido con `asyncio` para una alta concurrencia y eficiencia en el manejo de I/O de red y la gesti√≥n de m√∫ltiples servidores de datos.
-   **Informes Automatizados**: Crea autom√°ticamente informes detallados en **JSON** (para archivo local), **Notion** (para espacios de trabajo colaborativos) y **Supabase** (para persistencia de datos a largo plazo).
-   **Ciclo de Vida Din√°mico de Keywords**: Implementa un ciclo de vida completo para las palabras clave: descubrimiento, puntuaci√≥n, investigaci√≥n activa y seguimiento hist√≥rico, todo gestionado a trav√©s de simples archivos JSON.
-   **Desacoplado y Estandarizado**: Utiliza el **Model Context Protocol (MCP)** para comunicarse con el servidor de cada plataforma, asegurando una interfaz estandarizada, modular y f√°cilmente extensible.
-   **Altamente Configurable**: Toda la configuraci√≥n (API keys, selecci√≥n de modelos de IA, rutas de archivos) se gestiona a trav√©s de un √∫nico archivo `.env` para facilitar la portabilidad y seguridad.

### üèõÔ∏è Arquitectura del Sistema

El sistema est√° dise√±ado con una arquitectura modular donde un orquestador central gestiona varios componentes especializados. La comunicaci√≥n con las fuentes de datos externas se estandariza a trav√©s de servidores MCP.

```mermaid
graph TD
    subgraph "Motor Principal"
        A[ai_trend_researcher.py] --> B{KeywordManager};
        A --> C{MCPClientManager};
        A --> D{DataProcessor};
        A --> E{ReportManager};
    end

    subgraph "Integraci√≥n IA"
        F[AIClientManager] -- Gestiona --> G[OpenAI, Gemini, Groq, ...];
        D -- Usa --> F;
    end

    subgraph "Fuentes de Datos (v√≠a MCP)"
        C -- Conecta a --> H[Servidor YouTube];
        C -- Conecta a --> I[Servidor GitHub];
        C -- Conecta a --> J[Servidor ArXiv];
        C -- Conecta a --> K[Web/HackerNews...];
        C -- Conecta a --> L[Servidor ResearchHub];
    end

    subgraph "Informes de Salida"
        E -- Genera --> M[Archivos JSON];
        E -- Genera --> N[P√°ginas en Notion];
        E -- Genera --> O[Registros en Supabase];
    end

    B --> A;
```

-   **Orquestador (`ai_trend_researcher.py`)**: El script principal que coordina todo el flujo de investigaci√≥n, desde la carga de keywords hasta la generaci√≥n de informes finales.
-   **Configuraci√≥n (`config_manager.py`)**: Carga y valida todas las variables de entorno y configuraciones de los servidores.
-   **Conectividad (`mcp_client_manager.py`)**: Gestiona el ciclo de vida (inicio, conexi√≥n, llamada, cierre) de todos los servidores MCP para las plataformas de datos.
-   **F√°brica de IA (`ai_client_manager.py`)**: Proporciona una interfaz unificada para interactuar con diversos proveedores de LLM.
-   **L√≥gica de Plataformas (`platform_handlers.py`)**: Contiene la l√≥gica espec√≠fica para consultar cada plataforma y estandarizar su respuesta.
-   **An√°lisis (`data_processor.py`)**: Utiliza LLMs y heur√≠sticas para extraer nuevas palabras clave, puntuarlas y generar recomendaciones accionables.
-   **Informes (`report_generator.py`)**: Crea los informes finales en todos los formatos soportados.
-   **Base de Datos de Keywords (`keyword_manager.py`)**: Administra el estado de las palabras clave a trav√©s de los ciclos de investigaci√≥n.

### üíª Stack Tecnol√≥gico

-   **Backend**: Python 3.9+
-   **Concurrencia**: `asyncio`
-   **Proveedores IA**: OpenAI, Google Gemini, Anthropic Claude, Groq, Ollama
-   **Protocolo de Herramientas**: Model Context Protocol (MCP)
-   **Dependencias**: `python-dotenv`, `aiofiles`, SDKs de proveedores (ej. `openai`, `google-generativeai`)
-   **Prerrequisitos**: Node.js & npm (para ejecutar servidores MCP de la comunidad v√≠a `npx`), Rust (opcional, para compilar el servidor `research_hub`)

### üõ†Ô∏è Instalaci√≥n y Configuraci√≥n

#### 1. Prerrequisitos

-   **Python 3.9+**
-   **Node.js y npm** (necesario para `npx`, que ejecuta los servidores MCP de la comunidad).
-   **Git**
-   (Opcional) **Compilador de Rust**, si deseas compilar el ejecutable de `research_hub` desde el c√≥digo fuente. Si no, puedes usar un binario precompilado.

#### 2. Clonar el Repositorio

```bash
git clone https://github.com/tu-usuario/tu-repositorio.git
cd tu-repositorio
```

#### 3. Instalar Dependencias de Python

Se recomienda encarecidamente utilizar un entorno virtual.

```bash
python -m venv venv
# En macOS/Linux:
source venv/bin/activate
# En Windows:
venv\Scripts\activate

pip install -r requirements.txt
```

#### 4. Configurar las Variables de Entorno

Este es el paso m√°s cr√≠tico.

1.  Crea tu archivo de entorno a partir del ejemplo:
    ```bash
    cp .env.example .env
    ```
2.  Abre el archivo `.env` y rellena tus claves de API y rutas. Solo necesitas rellenar las claves para los servicios que vayas a utilizar.

    ```env
    # .env

    # --- Configuraci√≥n del Proveedor de IA ---
    # Elige uno: "openai", "gemini", "groq", "anthropic", "ollama"
    AI_PROVIDER="openai"

    # Rellena las claves de API para los proveedores que puedas usar.
    OPENAI_API_KEY="sk-..."
    GOOGLE_API_KEY="AIzaSy..."
    GROQ_API_KEY="gsk_..."
    ANTHROPIC_API_KEY="sk-ant-..."
    # No se necesita clave para Ollama

    # --- (Opcional) Modelos Espec√≠ficos de IA ---
    AI_MODEL_OPENAI="gpt-4o"
    AI_MODEL_GEMINI="gemini-1.5-flash"
    # ... etc. para otros proveedores

    # --- Claves de API para Fuentes de Datos ---
    YOUTUBE_API_KEY=AIzaSy...
    GITHUB_PERSONAL_ACCESS_TOKEN=ghp_...

    # --- Claves de API para Salidas de Informes ---
    NOTION_API_KEY=secret_...
    NOTION_PARENT_PAGE_ID=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
    SUPABASE_ACCESS_TOKEN=eyJhbGciOi...

    # --- Configuraci√≥n de Rutas del Sistema (¬°IMPORTANTE!) ---
    # DEBEN ser rutas absolutas.
    RESEARCH_PAPERS_DIR="/ruta/en/tu/maquina/research-papers"
    RESEARCH_HUB_EXECUTABLE="/ruta/en/tu/maquina/rust-research-mcp"
    ```

#### 5. Configurar la Base de Datos (Supabase)

Si planeas usar la integraci√≥n con Supabase, aseg√∫rate de que tu tabla en la base de datos coincida con el esquema definido en `supabase_schema.sql`. Puedes ejecutar ese script en el editor SQL de tu proyecto de Supabase.

### ‚ñ∂Ô∏è Uso

El proyecto tiene dos flujos de ejecuci√≥n principales.

#### 1. Investigaci√≥n Diaria de Tendencias

Este es el flujo de trabajo principal. Ejecuta la investigaci√≥n en todas las plataformas habilitadas usando las palabras clave de `keywords/active.json`, analiza los datos, descubre nuevas keywords y genera informes.

```bash
python ai_trend_researcher.py
```
El script registrar√° su progreso en la consola. Cuando finalice, encontrar√°s:
- Un informe JSON en el directorio `reports/`.
- Una nueva p√°gina en tu espacio de trabajo de Notion (si est√° configurado).
- Un nuevo registro en tu tabla de Supabase (si est√° configurado).

#### 2. Inmersi√≥n Profunda de Investigaci√≥n (`research_assistant`)

Este script avanzado utiliza el servidor personalizado `research_hub` para realizar investigaciones acad√©micas en profundidad. Busca *papers*, descarga los PDF y genera bibliograf√≠as.

1. Aseg√∫rate de que la ruta `RESEARCH_HUB_EXECUTABLE` en tu `.env` sea correcta.
2. A√±ade t√©rminos de b√∫squeda al archivo `terminos.txt` (uno por l√≠nea).

```bash
python research_assistant.py
```
Los resultados (CSVs, JSONs, archivos BibTeX y logs) se guardar√°n en un subdirectorio con marca de tiempo dentro de `salidas/` para mantener cada ejecuci√≥n organizada.

### ü§ù Contribuciones

¬°Las contribuciones son bienvenidas! Si tienes ideas para mejorar el proyecto, nuevas plataformas para integrar o encuentras alg√∫n error, por favor abre un *issue* o env√≠a un *pull request*.

### üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT. Consulta el archivo `LICENSE` para m√°s detalles.

---

<a name="-catal√†"></a>
## CAT Catal√†

<details>
<summary><strong>Taula de Continguts</strong></summary>

- [üöÄ Caracter√≠stiques Principals](#-caracter√≠stiques-principals-2)
- [üèõÔ∏è Arquitectura del Sistema](#Ô∏è-arquitectura-del-sistema-1)
- [üíª Stack Tecnol√≤gic](#-stack-tecnol√≤gic-1)
- [üõ†Ô∏è Instal¬∑laci√≥ i Configuraci√≥](#Ô∏è-installaci√≥-i-configuraci√≥-2)
- [‚ñ∂Ô∏è √ös](#Ô∏è-√∫s-2)
- [ü§ù Contribucions](#-contribucions-2)
- [üìÑ Llic√®ncia](#-llic√®ncia-2)

</details>

### AI Trend Research Engine

Un sistema automatitzat i modular per a la investigaci√≥ de tend√®ncies en Intel¬∑lig√®ncia Artificial. Recopila i processa dades de m√∫ltiples plataformes (GitHub, YouTube, ArXiv, etc.), utilitza models de llenguatge (LLMs) per extreure *insights*, descobrir noves paraules clau i genera informes complets en m√∫ltiples formats (JSON, Notion, Supabase).

**Nota:** Aquest projecte ha estat desenvolupat modificant el projecte [EmpowerHerDev/ai-trend-research-system](https://github.com/EmpowerHerDev/ai-trend-research-system) i integrant el servidor de recerca personalitzat de [Ladvien/research_hub_mcp](https://github.com/Ladvien/research_hub_mcp). El resultat √©s un sistema flexible i modular que ara √©s compatible amb m√∫ltiples prove√Ødors de models de llenguatge grans (LLM), incloent-hi **OpenAI (GPT), Google (Gemini), Anthropic (Claude), Groq i Ollama**. Aquest treball tambi√©n forma part d'un proc√©s d'aprenentatge personal en el camp del desenvolupament d'agents d'intel¬∑lig√®ncia artificial.

### üöÄ Caracter√≠stiques Principals

-   **Recerca Multiplataforma**: Recopila dades de YouTube, GitHub, cerques web, ArXiv, HackerNews i un motor de recerca de *papers* personalitzat.
-   **Suport Multi-LLM**: Canvia f√†cilment entre diferents prove√Ødors de LLM com OpenAI, Gemini, Groq, Anthropic i models locals amb Ollama.
-   **An√†lisi amb IA**: Utilitza LLMs per a tasques avan√ßades com l'extracci√≥ intel¬∑ligent de paraules clau, la generaci√≥ de recomanacions din√†miques i la traducci√≥ de consultes multiling√ºes.
-   **Arquitectura As√≠ncrona**: Constru√Øt amb `asyncio` per a una alta concurr√®ncia i efici√®ncia en la gesti√≥ d'I/O de xarxa i la gesti√≥ de m√∫ltiples servidors de dades.
-   **Informes Automatitzats**: Crea autom√†ticament informes detallats en **JSON** (per a arxiu local), **Notion** (per a espais de treball col¬∑laboratius) i **Supabase** (per a persist√®ncia de dades a llarg termini).
-   **Cicle de Vida Din√†mic de Keywords**: Implementa un cicle de vida complet per a les paraules clau: descobriment, puntuaci√≥, recerca activa i seguiment hist√≤ric, tot gestionat a trav√©s de simples fitxers JSON.
-   **Desacoblat i Estandarditzat**: Utilitza el **Model Context Protocol (MCP)** per comunicar-se amb el servidor de cada plataforma, assegurant una interf√≠cie estandarditzada, modular i f√†cilment extensible.
-   **Altament Configurable**: Tota la configuraci√≥ (claus d'API, selecci√≥ de models d'IA, rutes de fitxers) es gestiona a trav√©s d'un √∫nic fitxer `.env` per facilitar la portabilitat i seguretat.

### üèõÔ∏è Arquitectura del Sistema

El sistema est√† dissenyat amb una arquitectura modular on un orquestrador central gestiona diversos components especialitzats. La comunicaci√≥ amb les fonts de dades externes s'estandarditza a trav√©s de servidors MCP.

```mermaid
graph TD
    subgraph "Motor Principal"
        A[ai_trend_researcher.py] --> B{KeywordManager};
        A --> C{MCPClientManager};
        A --> D{DataProcessor};
        A --> E{ReportManager};
    end

    subgraph "Integraci√≥ IA"
        F[AIClientManager] -- Gestiona --> G[OpenAI, Gemini, Groq, ...];
        D -- Utilitza --> F;
    end

    subgraph "Fonts de Dades (via MCP)"
        C -- Connecta a --> H[Servidor YouTube];
        C -- Connecta a --> I[Servidor GitHub];
        C -- Connecta a --> J[Servidor ArXiv];
        C -- Connecta a --> K[Web/HackerNews...];
        C -- Connecta a --> L[Servidor ResearchHub];
    end

    subgraph "Informes de Sortida"
        E -- Genera --> M[Fitxers JSON];
        E -- Genera --> N[P√†gines a Notion];
        E -- Genera --> O[Registres a Supabase];
    end

    B --> A;
```

-   **Orquestrador (`ai_trend_researcher.py`)**: L'script principal que coordina tot el flux de recerca, des de la c√†rrega de paraules clau fins a la generaci√≥ d'informes finals.
-   **Configuraci√≥ (`config_manager.py`)**: Carrega i valida totes les variables d'entorn i configuracions dels servidors.
-   **Connectivitat (`mcp_client_manager.py`)**: Gestiona el cicle de vida (inici, connexi√≥, trucada, tancament) de tots els servidors MCP per a les plataformes de dades.
-   **F√†brica d'IA (`ai_client_manager.py`)**: Proporciona una interf√≠cie unificada per interactuar amb diversos prove√Ødors de LLM.
-   **L√≤gica de Plataformes (`platform_handlers.py`)**: Cont√© la l√≤gica espec√≠fica per consultar cada plataforma i estandarditzar la seva resposta.
-   **An√†lisi (`data_processor.py`)**: Utilitza LLMs i heur√≠stiques per extreure noves paraules clau, puntuar-les i generar recomanacions accionables.
-   **Informes (`report_generator.py`)**: Crea els informes finals en tots els formats suportats.
-   **Base de Dades de Keywords (`keyword_manager.py`)**: Administra l'estat de les paraules clau a trav√©s dels cicles de recerca.

### üíª Stack Tecnol√≤gic

-   **Backend**: Python 3.9+
-   **Concurr√®ncia**: `asyncio`
-   **Prove√Ødors IA**: OpenAI, Google Gemini, Anthropic Claude, Groq, Ollama
-   **Protocol d'Eines**: Model Context Protocol (MCP)
-   **Depend√®ncies**: `python-dotenv`, `aiofiles`, SDKs de prove√Ødors (ex. `openai`, `google-generativeai`)
-   **Prerequisits**: Node.js & npm (per executar servidors MCP de la comunitat via `npx`), Rust (opcional, per compilar el servidor `research_hub`)

### üõ†Ô∏è Instal¬∑laci√≥ i Configuraci√≥

#### 1. Prerequisits

-   **Python 3.9+**
-   **Node.js i npm** (necessari per a `npx`, que executa els servidors MCP de la comunitat).
-   **Git**
-   (Opcional) **Compilador de Rust**, si vols compilar l'executable de `research_hub` des del codi font. Si no, pots fer servir un binari precompilat.

#### 2. Clonar el Repositori

```bash
git clone https://github.com/el-teu-usuari/el-teu-repositori.git
cd el-teu-repositori
```

#### 3. Instal¬∑lar Depend√®ncies de Python

√âs molt recomanable utilitzar un entorn virtual.

```bash
python -m venv venv
# A macOS/Linux:
source venv/bin/activate
# A Windows:
venv\Scripts\activate

pip install -r requirements.txt
```

#### 4. Configurar les Variables d'Entorn

Aquest √©s el pas m√©s cr√≠tic.

1.  Crea el teu fitxer d'entorn a partir de l'exemple:
    ```bash
    cp .env.example .env
    ```
2.  Obre el fitxer `.env` i omple les teves claus d'API i rutes. Nom√©s cal omplir les claus per als serveis que vulguis utilitzar.

    ```env
    # .env

    # --- Configuraci√≥ del Prove√Ødor d'IA ---
    # Tria'n un: "openai", "gemini", "groq", "anthropic", "ollama"
    AI_PROVIDER="openai"

    # Omple les claus d'API per als prove√Ødors que puguis utilitzar.
    OPENAI_API_KEY="sk-..."
    GOOGLE_API_KEY="AIzaSy..."
    GROQ_API_KEY="gsk_..."
    ANTHROPIC_API_KEY="sk-ant-..."
    # No cal clau per a Ollama

    # --- (Opcional) Models Espec√≠fics d'IA ---
    AI_MODEL_OPENAI="gpt-4o"
    AI_MODEL_GEMINI="gemini-1.5-flash"
    # ... etc. per a altres prove√Ødors

    # --- Claus d'API per a Fonts de Dades ---
    YOUTUBE_API_KEY=AIzaSy...
    GITHUB_PERSONAL_ACCESS_TOKEN=ghp_...

    # --- Claus d'API per a Sortides d'Informes ---
    NOTION_API_KEY=secret_...
    NOTION_PARENT_PAGE_ID=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
    SUPABASE_ACCESS_TOKEN=eyJhbGciOi...

    # --- Configuraci√≥ de Rutes del Sistema (IMPORTANT!) ---
    # HAN de ser rutes absolutes.
    RESEARCH_PAPERS_DIR="/ruta/a/la/teva/maquina/research-papers"
    RESEARCH_HUB_EXECUTABLE="/ruta/a/la/teva/maquina/rust-research-mcp"
    ```

#### 5. Configurar la Base de Dades (Supabase)

Si planeges fer servir la integraci√≥ amb Supabase, assegura't que la teva taula a la base de dades coincideixi amb l'esquema definit a `supabase_schema.sql`. Pots executar aquest script a l'editor SQL del teu projecte de Supabase.

### ‚ñ∂Ô∏è √ös

El projecte t√© dos fluxos d'execuci√≥ principals.

#### 1. Recerca Di√†ria de Tend√®ncies

Aquest √©s el flux de treball principal. Executa la recerca a totes les plataformes habilitades fent servir les paraules clau de `keywords/active.json`, analitza les dades, descobreix noves keywords i genera informes.

```bash
python ai_trend_researcher.py
```
L'script registrar√† el seu progr√©s a la consola. Quan acabi, trobar√†s:
- Un informe JSON al directori `reports/`.
- Una nova p√†gina al teu espai de treball de Notion (si est√† configurat).
- Un nou registre a la teva taula de Supabase (si est√† configurat).

#### 2. Immersi√≥ Profunda de Recerca (`research_assistant`)

Aquest script avan√ßat utilitza el servidor personalitzat `research_hub` per a realitzar recerques acad√®miques en profunditat. Cerca *papers*, descarrega els PDF i genera bibliografies.

1. Assegura't que la ruta `RESEARCH_HUB_EXECUTABLE` al teu `.env` sigui correcta.
2. Afegeix termes de cerca al fitxer `terminos.txt` (un per l√≠nia).

```bash
python research_assistant.py
```
Els resultats (CSVs, JSONs, fitxers BibTeX i logs) es desaran en un subdirectori amb marca de temps dins de `salidas/` per mantenir cada execuci√≥ organitzada.

### ü§ù Contribucions

Les contribucions s√≥n benvingudes! Si tens idees per millorar el projecte, noves plataformes per integrar o trobes algun error, si us plau obre un *issue* o envia un *pull request*.

### üìÑ Llic√®ncia

Aquest projecte est√† sota la Llic√®ncia MIT. Consulta el fitxer `LICENSE` per a m√©s detalls.
